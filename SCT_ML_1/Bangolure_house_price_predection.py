# -*- coding: utf-8 -*-
"""BangolureHousePricePredection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10BYfO90NG-XbUbmH_nePsFv8M7eOqO72
"""

# import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import json
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression,Lasso,Ridge
from sklearn.preprocessing import OneHotEncoder,StandardScaler
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline
from sklearn.metrics import r2_score
from sklearn.preprocessing import StandardScaler

# Load Dataset into colab
df = pd.read_csv('/content/Bengaluru_House_Data.csv')

# Look at head of  the dataset
df.head()

# look at the bottom of the dataset
df.tail()

# look at the shape of dataset
df.shape

# Lets looka the summary of the dataset
df.info()

# For each column value counts
for columns in df.columns:
  print(df[columns].value_counts())

# Find the null values
df.isna().sum()

# drop the unwanted columns
df.drop(columns = ['area_type','availability','society','balcony'],inplace = True)

# summary of the dataset
df.describe()

# Summary in tabular column
df.describe().T

# summary of each colums
df.describe(include='all')

# info of the dataset
df.info()

"""# filling null values"""

# Value counts for location
df['location'].value_counts()

# fill the null values
df['location'] = df['location'].fillna('Sarjapur  Road')

df['size'].value_counts()

df['size'] = df['size'].fillna('2 BHK')

df['bath'] = df['bath'].fillna(df['bath'].median())

df.info()

df['bhk'] = df['size'].str.split().str.get(0).astype(int)

df[df.bhk>20]

df['total_sqft'].unique()

def convertrange(x):

        temp = x.split('-')
        if len(temp) == 2:
            return (float(temp[0])+float(temp[1]))/2
        try:
            return float(x)
        except:
            return None

df['total_sqft'] = df['total_sqft'].apply(convertrange)

df.head()

"""# price for srft"""

df['price_per_sqft'] = df['price']*100000/df['total_sqft']

df['price_per_sqft']

df.describe()

df['location'].value_counts()

df['location'] = df['location'].apply(lambda x: x.strip())
location_count = df['location'].value_counts()

location_count

location_count_less_10 = location_count[location_count <= 10]
location_count_less_10

df['location'] = df['location'].apply(lambda x: 'other' if x in location_count_less_10 else x)

df['location'].value_counts()

"""# Outlier Detection"""

df.describe()

(df['total_sqft']/df['bhk']).describe()

df = df[((df['total_sqft']/df['bhk'])>=300)]
df.describe()

df.shape

df.price_per_sqft.describe()

def remove_pps_outliers(df):
  df_out = pd.DataFrame()
  for key,subdf in df.groupby('location'):
    m = np.mean(subdf.price_per_sqft)

    st = np.std(subdf.price_per_sqft)

    gen_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft <= (m+st))]
    df_out = pd.concat([df_out,gen_df],ignore_index = True)
  return df_out
df = remove_pps_outliers(df)
df.describe()

def bhk_outlier_remover(df):
  exclude_index = np.array([])
  for location,location_df in df.groupby('location'):
    bhk_stats = {}
    for bhk,bhk_df in location_df.groupby('bhk'):
      bhk_stats[bhk] = {
          'mean': np.mean(bhk_df.price_per_sqft),
          'std': np.std(bhk_df.price_per_sqft),
          'count': bhk_df.shape[0]
      }
    for bhk,bhk_df in location_df.groupby('bhk'):
      stats = bhk_stats.get(bhk-1)
      if stats and stats['count']>5:
        exclude_index = np.append(exclude_index,bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)
    return df.drop(exclude_index,axis = 'index')

df = bhk_outlier_remover(df)

df.shape

df

df.drop(columns = ['size','price_per_sqft'],inplace = True)

df

"""# Cleaned data"""

df.to_csv('Cleaned_data.csv')

"""# Train the data"""

X = df.drop(columns = ['price'])
y = df['price']

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)

print(X_train.shape)
print(X_test.shape)

"""# Apply Linear Regression"""

column_trans = make_column_transformer((OneHotEncoder(sparse=False),['location']),
                                       remainder='passthrough')

scaler = StandardScaler()

lr = LinearRegression()

pipe = make_pipeline(column_trans,scaler,lr)

pipe.fit(X_train,y_train)

y_prdt_lr = pipe.predict(X_test)

r2_score(y_test,y_prdt_lr)

"""# Lasso"""

lasso =Lasso()

pipe = make_pipeline(column_trans,scaler,lasso)

pipe.fit(X_train,y_train)

y_prdt_lasso = pipe.predict(X_test)

r2_score(y_test,y_prdt_lasso)

"""# Ridge

"""

ridge = Ridge()

pipe = make_pipeline(column_trans,scaler,ridge)

pipe.fit(X_train,y_train)

y_prdt_ridge = pipe.predict(X_test)

r2_score(y_test,y_prdt_ridge)

print("No Regularization : " ,r2_score(y_test,y_prdt_lr))
print("Lasso : ", r2_score(y_test,y_prdt_lasso))
print("Ridge : " ,r2_score(y_test,y_prdt_ridge))